
  
---
title: "Time series *plastics* with Holt-Winters algorithms"
author: "Matthew O'Callaghan"
date: " 2019 "
output: 
   html_document: 
      number_sections: TRUE
   
---
<!-- ----------------------------------------------- --> 

```{r setup, include=FALSE,warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<!-- ----------------------------------------------- --> 
<!-- ----------------DATA IMPORT-------------------- --> 
<!-- ----------------------------------------------- --> 
***
# Plastics Data:

<font size="3">
According to page 39 of the 'fma' package [documentation ](www.https://cloud.r-project.org/web/packages/fma/fma.pdf) we have the following information about the date we are using throughout this assignment: 

* **Description**
  + Monthly sales of product A for a plastics  manufacturer.
* **Usage**
  + plastics
* **Format**
  + Time series data
  
<br>

```{r message=FALSE}
# Importing forecasting package where plastics is contained and preferred plotting package:
require("fma")
require("ggplot2")
plastics
```

<br>


The data is thus monthly, taken over a five year period. We assume all necessary Month Length Adjustments or Trading Day Adjustments have been made. Moreover we will assume that the value of sales indicates units sold.



***  

<br>

<!-- ----------------------------------------------- --> 
<!-- ------------DATA VISUALISATION------------------ -->
<!-- ----------------------------------------------- --> 



# Data Visualisation:
## Time Plot

We first look at the full time-series plot of the data:

<br>

```{r message=FALSE, fig.align = 'center'}
autoplot(plastics) + ggtitle("Monthly sales of product A for a plastics manufacturer. ") +
  xlab("Time in Years") + ylab("Sales")
```


<br><br>

There are a few visual quilities which are evident from the time series plot:

* There is a clear seasonality which appears to be a yearly cycle.
  + The seasonality indicates an minimum around February at the start of each year, followed by a ramping period towards reaching a peak around September. This is then followed by a decrease in sales toward the end of each year. 
  + This pattern could be due to the increased demand of retailers buying from a manufacturer to prepare for the Christmas period, then subsequently dropping in order to sell off existing stock.  
* There is a steady upward trend.
  +This could reflect an increase in demand for the product.
* There are small visual irregularities in the time series: a sharp change near the end of year two and halfway through year three.
  + A possible explanation for sharp changes in the time-series could be a labour strike or adverse weather conditions preventing work.


A visual inspection gives us a good idea as to the nature of the time-series. However, further analysis is needed to understand the data correctly 
<br><br>


## Seasonality Analysis:
The time-series plot indicates that there is seasonality. We now look at the seasonal plot and the seasonal subplot of the plastics data:

<br>


```{r message=FALSE, fig.align = 'center'}
ggseasonplot(plastics, year.labels=TRUE, year.labels.left=TRUE) +
  ylab("Sales") +
  ggtitle("Seasonal plot: Plastics")
ggsubseriesplot(plastics) +
  ylab("Sales") +
  ggtitle("Seasonal subseries plot: Plastics")
```


<br>

* The seaonal plot and the seasonal subseries plot reflects that the time-series is seasonal but its seasonality decreases from September onwards in the final year.
  + The decrease in seasonality in the fifth year can be also seen in the increase of error in the decomposition of the time series in section 2.4.
  + This may be due to product A becoming dated, or the introduction of a competing manufacturer for a similar product, in it's fifth year and becoming less lucrative to customers and thus retailers.
  
* We see that in year 5 the sales take a similar maximum to the previous year; however this occurs in June. This disaggrees with the seasonal pattern and the upwards trajectory of the trend. The sales figures then taper off earlier than usual, however they decrease in a steadier manner.

* The vertical movement of both plots up the y axis at each month confirms our visual inspection of increasing trend.
<br><br>

## Autocorrelation:

We analyse the lagplot, the ACF and the PACF to understand the correlation between the time-series and it's lagged time-series.

<br>

First we consider the lag plot:
```{r message=FALSE, fig.align = 'center'}
gglagplot(plastics)
```


<br>

* The lag plot in lag 12 illustrates a strong correlation between values $y_t$ and $y_{t-12}$. Tis reflects the stong seasonality over a 12 month basis.
* The lag plot in lag 1 strenthens the idea that there is an increasing trend as it indicates a correlation between $y_t$ and $y_{t-1}$.
* The irregularities in the plot from month 10 to 12 reflect the irregularities in year 5 previously discussed.

<br>

Now looking at the timeplot, ACF and PACF plot:

```{r message=FALSE, fig.align = 'center'}
tsdisplay(plastics)
```



<br>

* The ACF has a large positive correlation for small lags, which confirms the trending nature of the data.
  + This is due to the fact that the ACF at lag 1 measures the correlation between successive values in the time series. 

* The ACF at lag 12 is large and positive. This again confirms the 12 month seasonal nature of the data.
  +This is due to the fact that the ACF at lag 12 measures the correlation between $y_t$ and $y_{t-12}$ values in the time series. 

<br>





Finally we plot our time series with a lag plot (of lag 12) overlayed:
<br>


```{r message=FALSE, fig.align = 'center'}
plot(plastics-mean(plastics),lwd="3")
lines(lag(plastics-mean(plastics),12),col="red",lwd=3)
```


<br>

This confirms the information previously extracted from the data

<br><br>


## Decomposing the Time-Series:

We can decompose the time series in order to get a better understanding of the trend, seasonal and random component.   

First we consider assume the additive model: 
$$Y[t]=T[t]+S[t]+e(t)$$
where $Y$ is the time series, $S$ is the seasonal component and $e$ is the error component; $t$ represents time.

<br>


```{r message=FALSE, fig.align = 'center'}
plot(decompose(plastics))
```


<br>

The seasonal and trending components agree with our previous analysis.



Now we consider the multiplicative model:  
$$Y[t]=T[t]\times S[t]\times e(t)$$

<br>


```{r message=FALSE, fig.align = 'center'}
plot(decompose(plastics,type="multiplicative"))
```


<br>

Again the seasonal and trending components agree with our previous analysis.


Now both the multiplicative and additive decompostion are almost identical, bar the error component. To see which is more useful we can check the SSE of the model fit with both forms of decomposition.





## Conclusion

The information we have learned from the time-series indicates that, because of the evident trend and seasonality, the best algorithm to use will be the Holt-Winters’ Exponential Smoothing with Seasonality. We shall check both the multiplicative model and the additive model.

# Fitting the Model
We begin by by fitting the Holt-Winters’ Exponential Smoothing with Seasonality.  

## Fitting the Holt-Winters’ Exponential Smoothing with Seasonality 

Here $\alpha, \beta, \gamma$ are not specified and the HW R function selects them on the minimal value of SSE.

Firstly we look at the multiplicative model:


```{r message=FALSE, fig.align = 'center'}
HoltWinters(plastics,seasonal = "multiplicative")
```

Next the additive model:

```{r message=FALSE, fig.align = 'center'}
HoltWinters(plastics)
```




Now we compare the two models by SSE:
```{r message=FALSE, fig.align = 'center'}
HoltWinters(plastics,seasonal = "multiplicative")$SSE
```

```{r message=FALSE, fig.align = 'center'}
HoltWinters(plastics)$SSE
```
Also compare the MAPEs of the two models:
```{r message=FALSE, fig.align = 'center'}
mean(abs(HoltWinters(plastics,seasonal = "multiplicative")$x - HoltWinters(plastics,seasonal = "multiplicative")$fitted)/HoltWinters(plastics,seasonal = "multiplicative")$x)
 
```

```{r message=FALSE, fig.align = 'center'}
mean(abs(HoltWinters(plastics)$x - HoltWinters(plastics)$fitted)/HoltWinters(plastics)$x)
 
```
Now the SSE indicates that we should use the additive model while the mape indicates we should use the multiplicative model. We are going to choose the model based on the SSE and go forward using the additive model.

## Predictions
### Using the definition
Using the formula
$$
F_{n+k} = (L_n+k \times b_n)\times S_{n+k-s}
$$
with $k=1$, $s=12$ as the seasonality is a 12 month cycle.
the prediction can be computed as follows

```{r message=FALSE}
k=1  # prediction computed 1 month ahead
s=12 # frequency 12 month 
Ln=HoltWinters(plastics, seasonal="additive")$coefficients[1]
bn=HoltWinters(plastics, seasonal="additive")$coefficients[2]
snk= HoltWinters(plastics, seasonal="additive")$coefficients[3]
(Ln+k*bn+snk)
```



Likewise prediction can be computed for $k=5$ months ahead from the last observation of the time series *plastics* : 

```{r message=FALSE}
k=5  # prediction computed 1 month ahead
s=12 # frequency 12 month 
Ln=HoltWinters(plastics, seasonal="additive")$coefficients[1]
bn=HoltWinters(plastics, seasonal="additive")$coefficients[2]
snk= HoltWinters(plastics, seasonal="additive")$coefficients[7]
(Ln+k*bn+snk)

```
### Using the *predict()* function
We can also use the in-built *predict()* function:

```{r message=FALSE}
predict(HoltWinters(plastics, seasonal="additive"),n.ahead=1)[1]

predict(HoltWinters(plastics, seasonal="additive"),n.ahead=5)[5]
```


### Using the *forecast()* function
We can also use the in-built *forecast()* function:

```{r message=FALSE}
forecast(HoltWinters(plastics, seasonal="additive"),h=1)
forecast(HoltWinters(plastics, seasonal="additive"),h=5)
```
## Plots of Forecast
We can plot the forecast:
```{r message=FALSE, fig.align = 'center'}
plot(forecast(HoltWinters(plastics, seasonal="additive")))
```

The prediction intervals are contained within the shaded region. Prediction intervals are given by $$\hat{y}_{T+k} \pm c \hat{\sigma_k}$$ where c is the probability coverage multiplier.


Moreover we can plot the forecast and compare it to the additive model to see the difference.





```{r message=FALSE, fig.align = 'center'}
fit1 <- hw(plastics,seasonal="additive")
fit2 <- hw(plastics,seasonal="multiplicative")
autoplot(plastics) +
  autolayer(fit1, series="HW additive forecasts", PI=FALSE) +
  autolayer(fit2, series="HW multiplicative forecasts",
    PI=FALSE) +
  xlab("Year") +
  ylab("Sales") +
  ggtitle("Plastics Sales") +
  guides(colour=guide_legend(title="Forecast"))
```

Thus we can see the projected forecast using the selected method.


## Residual Diagnostics
```{r message=FALSE, fig.align = 'center'}
res<-residuals(HoltWinters(plastics, seasonal="additive"))
ggAcf(res)
mean(res)

```

This shows that our method produces a forecast that appear to account for all available information. The mean of the residuals is relatively close to zero and there is no significant correlation in the residuals. The 
</font>